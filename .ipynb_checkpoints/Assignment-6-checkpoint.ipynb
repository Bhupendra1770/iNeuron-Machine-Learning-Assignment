{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d4bc94",
   "metadata": {},
   "source": [
    "### 1. In the sense of machine learning, what is a model? What is the best way to train a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdbd589",
   "metadata": {},
   "source": [
    "Ans: Machine learning models are computer programs that are used to recognize patterns in data or make predictions. Machine learning models are created from machine learning algorithms, which are trained using either labeled, unlabeled, or mixed data.\n",
    "- Step 1: Begin with existing data:Machine learning requires us to have existing data—not the data our application will use when we run it, but data to learn from. You need a lot of real data, in fact, the more the better.\n",
    "  \n",
    "- Step 2: check data balance or not or check distrubution of data or try to remove outlier means try to clear data as much as possible before giving to model.\n",
    "\n",
    "- Step 3: Analyze data to identify patterns.\n",
    "\n",
    "- step 4: Choose machine learning algorithm according to problem statement.\n",
    "\n",
    "- step 5: Train model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aed7c6",
   "metadata": {},
   "source": [
    "### 2. In the sense of machine learning, explain the \"No Free Lunch\" theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3019c24",
   "metadata": {},
   "source": [
    "Ans: All of this theory is great, but what does''no free lunc'' mean for us as a data scientist, a machine learning engineer, or someone who just wants to get started with machine learning?\n",
    "\n",
    "Does it mean that all algorithms are equal? No, of course not. In practice, all algorithms are not created equal. This is because the entire set of machine learning problems is a theoretical concept in the NFL theorem and it is much larger than the set of practical machine learning problems that we will actually attempt to solve. Some algorithms may generally perform better than others on certain types of problems, but every algorithm has disadvantages and advantages due to the prior assumptions that come with that algorithm.\n",
    "\n",
    "An algorithm like XGBoost may win hundreds of Kaggle competitions yet fail miserably at forecasting tasks because of the limiting assumptions involved in tree-based models. Neural networks may perform really well when it comes to complex tasks like image classification and speech detection, yet suffer from overfitting due to their complexity if not trained properly.\n",
    "\n",
    "In practice, this is what “no free lunch” means for you:\n",
    "\n",
    "- No single algorithm will solve all your machine learning problems better than every other algorithm.\n",
    "- Make sure you completely understand a machine learning problem and the data involved before selecting an algorithm to use.\n",
    "- All models are only as good as the assumptions that they were created with and the data that was used to train them.\n",
    "- Simpler models like logistic regression have more bias and tend to underfit, while more complex models like neural networks have more variance and tend to overfit.\n",
    "- The best models for a given problem are somewhere in the middle of the two bias-variance extremes.\n",
    "- To find a good model for a problem, you may have to try different models and compare them using a robust cross-validation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3fbb7",
   "metadata": {},
   "source": [
    "### 3. Describe the K-fold cross-validation mechanism in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098654b4",
   "metadata": {},
   "source": [
    "Ans: K-fold Cross-Validation is when the dataset is split into a K number of folds and is used to evaluate the model's ability when given new data. K refers to the number of groups the data sample is split into. For example, if you see that the k-value is 5, we can call this a 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e73dd3",
   "metadata": {},
   "source": [
    "### 4. Describe the bootstrap sampling method. What is the aim of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b19d7",
   "metadata": {},
   "source": [
    "Ans: Particularly useful for assessing the quality of a machine learning model, bootstrapping is a method of inferring results for a population from results found on a collection of smaller random samples of the population, using replacement during the sampling process.This approach to sampling is called sampling with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f376e7a",
   "metadata": {},
   "source": [
    "### 5. What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a181d4",
   "metadata": {},
   "source": [
    "Ans: Kappa value or Cohen's Kappa coefficient is an evaluation metric for classification models. Its significance as an evaluation metric is that it can be used to evaluate multi class classification models and also works on models trained on imbalanced datasets(scores like accuracy scores fail for imbalanced datasets).\n",
    "\n",
    "In simpler words It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. Cohen's kappa is always less than or equal to 1. Values of 0 or less, indicate that the classifier is useless Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33446f4f",
   "metadata": {},
   "source": [
    "### 6. Describe the model ensemble method. In machine learning, what part does it play?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57601efb",
   "metadata": {},
   "source": [
    "Ans: Ensemble methods or ensemble machine learning models are models where more than one models are being used spontaneously to produce better results than individually trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173e02c",
   "metadata": {},
   "source": [
    "### 7. What is a descriptive model's main purpose? Give examples of real-world problems that descriptive models were used to solve.\n",
    "Ans: A descriptive model is used for tasks that would benefit from the insight gained from summarizing data in new and interesting ways. As opposed to predictive models that predict a target of interest, in a descriptive model, no single feature is more important than any other. In fact, because there is no target to learn, the process of training a descriptive model is called unsupervised learning.\n",
    "\n",
    "It is used in customer classification as real life problem ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be812088",
   "metadata": {},
   "source": [
    "### 8. Describe how to evaluate a linear regression model.\n",
    "Ans: Evaluation of a linear regression model can be done using R-square. R square is calculated as the sum of squared errors in predictions made, divided by summation of all sum of squares. R square measures how much of the change in target variable can be explained by the linear regressor. Its value ranges from 0 to 1 where 0 means poor performance and 1 means good. Some other techniques which can be used to evaluate a linear regression model are:\n",
    "\n",
    "Mean Square Error(MSE)/Root Mean Square Error(RMSE)\n",
    "Mean Absolute Error(MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab61a5",
   "metadata": {},
   "source": [
    "### 9. Distinguish :\n",
    "1. Descriptive vs. predictive models\n",
    "2. Underfitting vs. overfitting the model\n",
    "3. Bootstrapping vs. cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb2401",
   "metadata": {},
   "source": [
    "Ans: The differences between:\n",
    "\n",
    "1. Descriptive vs. predictive models\n",
    "\n",
    "- Descriptive models are built to identify trends and underlying patterns.\n",
    "- Predictive models are built to predict a dependent variable value.\n",
    "- Most of descriptive models are built using unsupervised machine learning.\n",
    "- Most of predictive models are built using classification and regression models.\n",
    "\n",
    "2. Underfitting vs. overfitting the model\n",
    "\n",
    "- Underfitting is a situation arising when the hypothesis is way too simple, or when the machine learning model is way too simple to produce good results.\n",
    "- Overfitting is a situation arising when the hypothesis is way too complex, or when the machine learning model is way too complex to produce good results.\n",
    "- Underfitting causes a model to produce poor results due to heavily simplified algorithm reacting lightly to changes in the unseen data for independent variables from the training data.\n",
    "- Overfitting makes a model produce poor results due to slightest variations in the unseen data for independent variables from the training data\n",
    "- Underfitting is also called High Bias.\n",
    "- Overfitting is also called High variance\n",
    "\n",
    "3. Bootstrapping vs cross-validation\n",
    "\n",
    "- Boostrap sampling is a method of sampling in which the repeated sampling is done with replacement using a data D in random draws over which machine learning models are trained for better performance.\n",
    "- Cross validation is a method used to check the efficacy of the machine learning model on test data.\n",
    "- End goal of bootstrapping is to reduce overfitting and increase performance.\n",
    "- End goal of cross validation is only to produce test scores to check efficacy of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249b699",
   "metadata": {},
   "source": [
    "### 10. Make quick notes on:\n",
    "- LOOCV.\n",
    "- F-measurement\n",
    "- The width of the silhouette\n",
    "- Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098708b",
   "metadata": {},
   "source": [
    "Ans: The Quick notes on: LOOCV or Leave One Out Cross Validation is a form of K-fold cross validation where only one observation is left out for validation purpose while the rest of the data is used for model training each iteration. It is computationally taxing and should only be used for data with low dimensionality.\n",
    "\n",
    "Harmonic mean of Precision score and recall score is called F-measurement or F-score. It is formulated as 2 (pr re)/pr +re where pr is precision score and re is recall score.\n",
    "\n",
    "Estimate of average inter cluster distance to give efficacy/performance of cluster algorithms is called width of the silhouette. It can also be defined as how identical/similar a data point 'x' is to the data points inside the cluster to which x is assigned. Its value ranges from -1 to 1 where 1 means good and -1 means bad.\n",
    "\n",
    "Curve plotted between True Positive Rate and False Positive Rate is Receiver Operating Characteristics curve and is used to find the area under the curve for ROC-AUC score for binary classification evaluation. True Positive Rate and False Positive Rate are calculated for different thresholds values where thresholds take values starting from the highest probability scores assigned to data points and goes up to the lowest probability score. The curve is impacted by presence of outliers, and simple models. Extensions can be made to this curve to suit multiclass classification evaluation requirements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
